{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a84b4f6",
   "metadata": {},
   "source": [
    "# Fetch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1998be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flops</th>\n",
       "      <th>active_params</th>\n",
       "      <th>total_params</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e18</td>\n",
       "      <td>82200000</td>\n",
       "      <td>239000000</td>\n",
       "      <td>3.365395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e18</td>\n",
       "      <td>219000000</td>\n",
       "      <td>995100000</td>\n",
       "      <td>3.332465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e19</td>\n",
       "      <td>33400000</td>\n",
       "      <td>72600000</td>\n",
       "      <td>3.397310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e19</td>\n",
       "      <td>82200000</td>\n",
       "      <td>239000000</td>\n",
       "      <td>3.135083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e19</td>\n",
       "      <td>37500000</td>\n",
       "      <td>100200000</td>\n",
       "      <td>3.307347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3e19</td>\n",
       "      <td>182700000</td>\n",
       "      <td>747100000</td>\n",
       "      <td>3.034445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3e19</td>\n",
       "      <td>354900000</td>\n",
       "      <td>1700000000</td>\n",
       "      <td>3.031785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3e19</td>\n",
       "      <td>98400000</td>\n",
       "      <td>349200000</td>\n",
       "      <td>3.079536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3e19</td>\n",
       "      <td>721200000</td>\n",
       "      <td>3800000000</td>\n",
       "      <td>3.035623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3e19</td>\n",
       "      <td>219000000</td>\n",
       "      <td>995100000</td>\n",
       "      <td>3.007967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3e19</td>\n",
       "      <td>146400000</td>\n",
       "      <td>499200000</td>\n",
       "      <td>3.064002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6e18</td>\n",
       "      <td>146400000</td>\n",
       "      <td>499200000</td>\n",
       "      <td>3.334804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6e18</td>\n",
       "      <td>98400000</td>\n",
       "      <td>349200000</td>\n",
       "      <td>3.332179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6e18</td>\n",
       "      <td>37500000</td>\n",
       "      <td>100200000</td>\n",
       "      <td>3.467462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6e18</td>\n",
       "      <td>721200000</td>\n",
       "      <td>3800000000</td>\n",
       "      <td>3.662520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6e18</td>\n",
       "      <td>354900000</td>\n",
       "      <td>1700000000</td>\n",
       "      <td>3.416493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6e18</td>\n",
       "      <td>182700000</td>\n",
       "      <td>747100000</td>\n",
       "      <td>3.339784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6e18</td>\n",
       "      <td>114500000</td>\n",
       "      <td>459400000</td>\n",
       "      <td>3.319643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6e18</td>\n",
       "      <td>419400000</td>\n",
       "      <td>2200000000</td>\n",
       "      <td>3.422772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6e18</td>\n",
       "      <td>866400000</td>\n",
       "      <td>4800000000</td>\n",
       "      <td>3.786210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6e18</td>\n",
       "      <td>33400000</td>\n",
       "      <td>72600000</td>\n",
       "      <td>3.539731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1e19</td>\n",
       "      <td>219000000</td>\n",
       "      <td>995100000</td>\n",
       "      <td>3.221049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1e19</td>\n",
       "      <td>419400000</td>\n",
       "      <td>2200000000</td>\n",
       "      <td>3.255508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1e19</td>\n",
       "      <td>114500000</td>\n",
       "      <td>459400000</td>\n",
       "      <td>3.205159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1e19</td>\n",
       "      <td>866400000</td>\n",
       "      <td>4800000000</td>\n",
       "      <td>3.403764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6e18</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>5800000000</td>\n",
       "      <td>4.159929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1e19</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>5800000000</td>\n",
       "      <td>3.487872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6e18</td>\n",
       "      <td>483900000</td>\n",
       "      <td>2600000000</td>\n",
       "      <td>3.503285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1e19</td>\n",
       "      <td>33400000</td>\n",
       "      <td>72600000</td>\n",
       "      <td>3.480588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1e19</td>\n",
       "      <td>146400000</td>\n",
       "      <td>499200000</td>\n",
       "      <td>3.231692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1e19</td>\n",
       "      <td>82200000</td>\n",
       "      <td>239000000</td>\n",
       "      <td>3.272088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1e19</td>\n",
       "      <td>483900000</td>\n",
       "      <td>2600000000</td>\n",
       "      <td>3.280053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1e19</td>\n",
       "      <td>98400000</td>\n",
       "      <td>349200000</td>\n",
       "      <td>3.228969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1e19</td>\n",
       "      <td>182700000</td>\n",
       "      <td>747100000</td>\n",
       "      <td>3.225399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1e19</td>\n",
       "      <td>721200000</td>\n",
       "      <td>3800000000</td>\n",
       "      <td>3.343157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6e18</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>8500000000</td>\n",
       "      <td>4.743215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1e19</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>8500000000</td>\n",
       "      <td>3.798542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3e19</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>8500000000</td>\n",
       "      <td>3.141646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3e19</td>\n",
       "      <td>1700000000</td>\n",
       "      <td>10300000000</td>\n",
       "      <td>3.197028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6e18</td>\n",
       "      <td>1700000000</td>\n",
       "      <td>10300000000</td>\n",
       "      <td>5.085556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1e19</td>\n",
       "      <td>354900000</td>\n",
       "      <td>1700000000</td>\n",
       "      <td>3.199815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1e19</td>\n",
       "      <td>1700000000</td>\n",
       "      <td>10300000000</td>\n",
       "      <td>4.100996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3e19</td>\n",
       "      <td>419400000</td>\n",
       "      <td>2200000000</td>\n",
       "      <td>2.997382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3e19</td>\n",
       "      <td>483900000</td>\n",
       "      <td>2600000000</td>\n",
       "      <td>3.042273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1e19</td>\n",
       "      <td>37500000</td>\n",
       "      <td>100200000</td>\n",
       "      <td>3.398764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3e19</td>\n",
       "      <td>866400000</td>\n",
       "      <td>4800000000</td>\n",
       "      <td>3.066026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3e19</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>5800000000</td>\n",
       "      <td>3.049857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3e19</td>\n",
       "      <td>114500000</td>\n",
       "      <td>459400000</td>\n",
       "      <td>3.043803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flops  active_params  total_params      loss\n",
       "0   6e18       82200000     239000000  3.365395\n",
       "1   6e18      219000000     995100000  3.332465\n",
       "2   3e19       33400000      72600000  3.397310\n",
       "3   3e19       82200000     239000000  3.135083\n",
       "4   3e19       37500000     100200000  3.307347\n",
       "5   3e19      182700000     747100000  3.034445\n",
       "6   3e19      354900000    1700000000  3.031785\n",
       "7   3e19       98400000     349200000  3.079536\n",
       "8   3e19      721200000    3800000000  3.035623\n",
       "9   3e19      219000000     995100000  3.007967\n",
       "10  3e19      146400000     499200000  3.064002\n",
       "11  6e18      146400000     499200000  3.334804\n",
       "12  6e18       98400000     349200000  3.332179\n",
       "13  6e18       37500000     100200000  3.467462\n",
       "14  6e18      721200000    3800000000  3.662520\n",
       "15  6e18      354900000    1700000000  3.416493\n",
       "16  6e18      182700000     747100000  3.339784\n",
       "17  6e18      114500000     459400000  3.319643\n",
       "18  6e18      419400000    2200000000  3.422772\n",
       "19  6e18      866400000    4800000000  3.786210\n",
       "20  6e18       33400000      72600000  3.539731\n",
       "21  1e19      219000000     995100000  3.221049\n",
       "22  1e19      419400000    2200000000  3.255508\n",
       "23  1e19      114500000     459400000  3.205159\n",
       "24  1e19      866400000    4800000000  3.403764\n",
       "25  6e18     1000000000    5800000000  4.159929\n",
       "26  1e19     1000000000    5800000000  3.487872\n",
       "27  6e18      483900000    2600000000  3.503285\n",
       "28  1e19       33400000      72600000  3.480588\n",
       "29  1e19      146400000     499200000  3.231692\n",
       "30  1e19       82200000     239000000  3.272088\n",
       "31  1e19      483900000    2600000000  3.280053\n",
       "32  1e19       98400000     349200000  3.228969\n",
       "33  1e19      182700000     747100000  3.225399\n",
       "34  1e19      721200000    3800000000  3.343157\n",
       "35  6e18     1500000000    8500000000  4.743215\n",
       "36  1e19     1500000000    8500000000  3.798542\n",
       "37  3e19     1500000000    8500000000  3.141646\n",
       "38  3e19     1700000000   10300000000  3.197028\n",
       "39  6e18     1700000000   10300000000  5.085556\n",
       "40  1e19      354900000    1700000000  3.199815\n",
       "41  1e19     1700000000   10300000000  4.100996\n",
       "42  3e19      419400000    2200000000  2.997382\n",
       "43  3e19      483900000    2600000000  3.042273\n",
       "44  1e19       37500000     100200000  3.398764\n",
       "45  3e19      866400000    4800000000  3.066026\n",
       "46  3e19     1000000000    5800000000  3.049857\n",
       "47  3e19      114500000     459400000  3.043803"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_count(s: str) -> int:\n",
    "    s = s.strip().upper()\n",
    "    if s.endswith(\"B\"):\n",
    "        return int(float(s[:-1]) * 1_000_000_000)\n",
    "    elif s.endswith(\"M\"):\n",
    "        return int(float(s[:-1]) * 1_000_000)\n",
    "    elif s.endswith(\"K\"):\n",
    "        return int(float(s[:-1]) * 1_000)\n",
    "    return int(float(s))\n",
    "\n",
    "\n",
    "api, data = wandb.Api(), []\n",
    "frontier = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/1sIr9HRwYbUXKzlskUTMorMa2A_cAzDwE0eUJnk-W1dQ/export?format=csv&gid=1059339506\"\n",
    ")\n",
    "\n",
    "for run in api.runs(\"haok/flame-moe\", {\"group\": {\"$regex\": \"ablation\"}}):\n",
    "    if run.state != \"finished\":\n",
    "        continue\n",
    "    flops = run.group.split(\"-\").pop()\n",
    "    loss = run.summary[\"lm loss validation\"]\n",
    "    num_layers, hidden_size = run.config[\"num_layers\"], run.config[\"hidden_size\"]\n",
    "    selected = frontier[\n",
    "        (frontier[\"num_layers\"] == num_layers)\n",
    "        & (frontier[\"hidden_size\"] == hidden_size)\n",
    "    ]\n",
    "    active_params, total_params = (\n",
    "        selected.iloc[0][\"active_params\"],\n",
    "        selected.iloc[0][\"total_params\"],\n",
    "    )\n",
    "    active_params, total_params = parse_count(active_params), parse_count(total_params)\n",
    "    data.append((flops, active_params, total_params, loss))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"flops\", \"active_params\", \"total_params\", \"loss\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c4346",
   "metadata": {},
   "source": [
    "# Optimize the Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7550c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [00:32<00:00, 137.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E     = 2.321319\n",
      "A     = 148.412879\n",
      "alpha = 0.282095\n",
      "B     = 485165195.409790\n",
      "beta  = 0.949377\n",
      "Loss   = 0.000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Define the scaling law model\n",
    "def scaling_law(params, N, D):\n",
    "    E, A, alpha, B, beta = params\n",
    "    return E + A / (N**alpha) + B / (D**beta)\n",
    "\n",
    "\n",
    "# Step 2: Define the loss function\n",
    "def mse_loss(params, N, D, targets):\n",
    "    preds = scaling_law(params, N, D)\n",
    "    return np.mean((preds - targets) ** 2)\n",
    "\n",
    "\n",
    "def huber_loss(params, N, D, targets, delta=1e-3):\n",
    "    preds = scaling_law(params, N, D)\n",
    "    error = np.log(targets) - np.log(preds)\n",
    "    is_small = np.abs(error) <= delta\n",
    "    squared = 0.5 * error**2\n",
    "    linear = delta * (np.abs(error) - 0.5 * delta)\n",
    "    return np.mean(np.where(is_small, squared, linear))\n",
    "\n",
    "\n",
    "# Step 3: Prepare your data\n",
    "N = df[\"active_params\"].values\n",
    "D = (df[\"flops\"].astype(float) / (6 * df[\"active_params\"])).values\n",
    "targets = df[\"loss\"].values\n",
    "\n",
    "# Step 4: Set an initial guess\n",
    "E_range = [exp(-1), exp(-0.5), exp(0), exp(0.5), exp(1.0)]\n",
    "A_range = [exp(0), exp(5), exp(10), exp(15), exp(20), exp(25)]\n",
    "alpha_range = [0, 0.5, 1, 1.5, 2]\n",
    "B_range = [exp(0), exp(5), exp(10), exp(15), exp(20), exp(25)]\n",
    "beta_range = [0, 0.5, 1, 1.5, 2]\n",
    "initial_guesses = list(product(E_range, A_range, alpha_range, B_range, beta_range))\n",
    "\n",
    "# Step 5: Fit using L-BFGS-B\n",
    "best_result = None\n",
    "lowest_mse = np.inf\n",
    "\n",
    "for guess in tqdm(initial_guesses):\n",
    "    result = minimize(huber_loss, x0=guess, args=(N, D, targets), method=\"L-BFGS-B\")\n",
    "    if result.success:\n",
    "        current_mse = huber_loss(result.x, N, D, targets)\n",
    "        if current_mse < lowest_mse:\n",
    "            lowest_mse = current_mse\n",
    "            best_result = result\n",
    "\n",
    "# Step 6: Show the results\n",
    "if best_result:\n",
    "    E_opt, A_opt, alpha_opt, B_opt, beta_opt = best_result.x\n",
    "    print(f\"E     = {E_opt:.6f}\")\n",
    "    print(f\"A     = {A_opt:.6f}\")\n",
    "    print(f\"alpha = {alpha_opt:.6f}\")\n",
    "    print(f\"B     = {B_opt:.6f}\")\n",
    "    print(f\"beta  = {beta_opt:.6f}\")\n",
    "    print(f\"Loss   = {lowest_mse:.6f}\")\n",
    "else:\n",
    "    print(\"Optimization failed for all initial guesses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765e362",
   "metadata": {},
   "source": [
    "# Find the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee1dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DCLM scale</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>padded_vocab_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>ffn_hidden_size</th>\n",
       "      <th>moe_ffn_hidden_size</th>\n",
       "      <th>num_experts</th>\n",
       "      <th>moe_router_topk</th>\n",
       "      <th>active_params</th>\n",
       "      <th>total_params</th>\n",
       "      <th>tokens</th>\n",
       "      <th>predicted_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400M-1x</td>\n",
       "      <td>2.000000e+19</td>\n",
       "      <td>12</td>\n",
       "      <td>50304</td>\n",
       "      <td>1024</td>\n",
       "      <td>5472</td>\n",
       "      <td>704</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>354.9M</td>\n",
       "      <td>1.7B</td>\n",
       "      <td>9.392317e+09</td>\n",
       "      <td>3.061320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400M-4x</td>\n",
       "      <td>8.000000e+19</td>\n",
       "      <td>18</td>\n",
       "      <td>50304</td>\n",
       "      <td>1536</td>\n",
       "      <td>8208</td>\n",
       "      <td>1056</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0B</td>\n",
       "      <td>5.8B</td>\n",
       "      <td>1.333333e+10</td>\n",
       "      <td>2.868918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1B-1x</td>\n",
       "      <td>2.400000e+20</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>1.600000e+10</td>\n",
       "      <td>2.752341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1B-3x</td>\n",
       "      <td>7.200000e+20</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>4.800000e+10</td>\n",
       "      <td>2.687829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3B-1x</td>\n",
       "      <td>9.400000e+20</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>6.266667e+10</td>\n",
       "      <td>2.679979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1B-5x</td>\n",
       "      <td>1.200000e+21</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>8.000000e+10</td>\n",
       "      <td>2.674339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7B-1x</td>\n",
       "      <td>5.700000e+21</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>3.800000e+11</td>\n",
       "      <td>2.657648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7B-2x</td>\n",
       "      <td>1.100000e+22</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>7.333333e+11</td>\n",
       "      <td>2.655362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DCLM scale         FLOPs  num_layers  padded_vocab_size  hidden_size  \\\n",
       "0    400M-1x  2.000000e+19          12              50304         1024   \n",
       "1    400M-4x  8.000000e+19          18              50304         1536   \n",
       "2      1B-1x  2.400000e+20          27              50304         2048   \n",
       "3      1B-3x  7.200000e+20          27              50304         2048   \n",
       "4      3B-1x  9.400000e+20          27              50304         2048   \n",
       "5      1B-5x  1.200000e+21          27              50304         2048   \n",
       "6      7B-1x  5.700000e+21          27              50304         2048   \n",
       "7      7B-2x  1.100000e+22          27              50304         2048   \n",
       "\n",
       "   ffn_hidden_size  moe_ffn_hidden_size  num_experts  moe_router_topk  \\\n",
       "0             5472                  704           64                8   \n",
       "1             8208                 1056           64                8   \n",
       "2            10944                 1408           64                8   \n",
       "3            10944                 1408           64                8   \n",
       "4            10944                 1408           64                8   \n",
       "5            10944                 1408           64                8   \n",
       "6            10944                 1408           64                8   \n",
       "7            10944                 1408           64                8   \n",
       "\n",
       "  active_params total_params        tokens  predicted_loss  \n",
       "0        354.9M         1.7B  9.392317e+09        3.061320  \n",
       "1          1.0B         5.8B  1.333333e+10        2.868918  \n",
       "2          2.5B        15.5B  1.600000e+10        2.752341  \n",
       "3          2.5B        15.5B  4.800000e+10        2.687829  \n",
       "4          2.5B        15.5B  6.266667e+10        2.679979  \n",
       "5          2.5B        15.5B  8.000000e+10        2.674339  \n",
       "6          2.5B        15.5B  3.800000e+11        2.657648  \n",
       "7          2.5B        15.5B  7.333333e+11        2.655362  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_count(s: str) -> int:\n",
    "    s = s.strip().upper()\n",
    "    if s.endswith(\"B\"):\n",
    "        return int(float(s[:-1]) * 1_000_000_000)\n",
    "    elif s.endswith(\"M\"):\n",
    "        return int(float(s[:-1]) * 1_000_000)\n",
    "    elif s.endswith(\"K\"):\n",
    "        return int(float(s[:-1]) * 1_000)\n",
    "    return int(float(s))\n",
    "\n",
    "\n",
    "def scaling_law(N, D):\n",
    "    # Obtained from MSE \n",
    "    # E, A, alpha, B, beta = 2.133594, 65.254366, 0.226854, 485165195.409790, 0.949495\n",
    "    # Obtained from Huber\n",
    "    E, A, alpha, B, beta = 2.321319, 148.412879, 0.282095, 485165195.409790, 0.949377\n",
    "    return E + A / (N**alpha) + B / (D**beta)\n",
    "\n",
    "\n",
    "# Step 1: Load and transform\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1sIr9HRwYbUXKzlskUTMorMa2A_cAzDwE0eUJnk-W1dQ/export?format=csv&gid=599230821\")\n",
    "\n",
    "# Step 2: Define budgets\n",
    "budgets = [6e18, 1e19, 3e19, 6e19, 1e20, 3e20, 6e20, 1e21, 3e21, 6e21]\n",
    "budgets = [2e19, 8e19, 2.4e20, 7.2e20, 9.4e20, 1.2e21, 5.7e21, 1.1e22]\n",
    "\n",
    "# Step 3: Compute predicted loss and best configs\n",
    "merged = []\n",
    "for budget in budgets:\n",
    "    df[\"FLOPs\"] = budget\n",
    "    df[\"tokens\"] = budget / (6 * df[\"active_params\"].apply(parse_count))\n",
    "    df[\"predicted_loss\"] = scaling_law(\n",
    "        df[\"active_params\"].apply(parse_count),\n",
    "        df[\"tokens\"],\n",
    "    )\n",
    "    tops = df.nsmallest(1, \"predicted_loss\")\n",
    "    merged.append(tops)\n",
    "\n",
    "df = pd.concat(merged, ignore_index=True)\n",
    "df[\"DCLM scale\"] = [\n",
    "    \"400M-1x\",\n",
    "    \"400M-4x\",\n",
    "    \"1B-1x\",\n",
    "    \"1B-3x\",\n",
    "    \"3B-1x\",\n",
    "    \"1B-5x\",\n",
    "    \"7B-1x\",\n",
    "    \"7B-2x\",\n",
    "]\n",
    "df = df[\n",
    "    [\"DCLM scale\", \"FLOPs\"]\n",
    "    + [col for col in df.columns if col != \"DCLM scale\" and col != \"FLOPs\"]\n",
    "]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megatron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
