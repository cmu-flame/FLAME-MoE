{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a84b4f6",
   "metadata": {},
   "source": [
    "# Fetch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1998be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "def parse_count(s: str) -> int:\n",
    "    s = s.strip().upper()\n",
    "    if s.endswith(\"B\"):\n",
    "        return int(float(s[:-1]) * 1_000_000_000)\n",
    "    elif s.endswith(\"M\"):\n",
    "        return int(float(s[:-1]) * 1_000_000)\n",
    "    elif s.endswith(\"K\"):\n",
    "        return int(float(s[:-1]) * 1_000)\n",
    "    return int(float(s))\n",
    "\n",
    "api, data = wandb.Api(), []\n",
    "frontier = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1sIr9HRwYbUXKzlskUTMorMa2A_cAzDwE0eUJnk-W1dQ/export?format=csv&gid=1059339506\")\n",
    "\n",
    "for run in api.runs(\"haok/flame-moe\", {\"group\": {\"$regex\": \"ablation\"}}):\n",
    "    if run.state != \"finished\": continue\n",
    "    flops = run.group.split(\"-\").pop()\n",
    "    loss = run.summary[\"lm loss validation\"]\n",
    "    num_layers, hidden_size = run.config[\"num_layers\"], run.config[\"hidden_size\"]\n",
    "    selected = frontier[(frontier[\"num_layers\"] == num_layers) & (frontier[\"hidden_size\"] == hidden_size)]\n",
    "    active_params, total_params = selected.iloc[0][\"active_params\"], selected.iloc[0][\"total_params\"]\n",
    "    active_params, total_params = parse_count(active_params), parse_count(total_params)\n",
    "    data.append((flops, active_params, total_params, loss))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"flops\", \"active_params\", \"total_params\", \"loss\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c4346",
   "metadata": {},
   "source": [
    "# Optimize the Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Define the scaling law model\n",
    "def scaling_law(params, N, D):\n",
    "    E, A, alpha, B, beta = params\n",
    "    return E + A / (N**alpha) + B / (D**beta)\n",
    "\n",
    "# Step 2: Define the loss function\n",
    "def mse_loss(params, N, D, targets):\n",
    "    preds = scaling_law(params, N, D)\n",
    "    return np.mean((preds - targets) ** 2)\n",
    "\n",
    "def huber_loss(params, N, D, targets, delta=1e-3):\n",
    "    preds = scaling_law(params, N, D)\n",
    "    error = np.log(targets) - np.log(preds)\n",
    "    is_small = np.abs(error) <= delta\n",
    "    squared = 0.5 * error**2\n",
    "    linear = delta * (np.abs(error) - 0.5 * delta)\n",
    "    return np.mean(np.where(is_small, squared, linear))\n",
    "\n",
    "# Step 3: Prepare your data\n",
    "N = df[\"active_params\"].values\n",
    "D = (df[\"flops\"].astype(float) / (6 * df[\"active_params\"])).values\n",
    "targets = df[\"loss\"].values\n",
    "\n",
    "# Step 4: Set an initial guess\n",
    "E_range = [exp(-1), exp(-0.5), exp(0), exp(0.5), exp(1.0)]\n",
    "A_range = [exp(0), exp(5), exp(10), exp(15), exp(20), exp(25)]\n",
    "alpha_range = [0, 0.5, 1, 1.5, 2]\n",
    "B_range = [exp(0), exp(5), exp(10), exp(15), exp(20), exp(25)]\n",
    "beta_range = [0, 0.5, 1, 1.5, 2]\n",
    "initial_guesses = list(product(E_range, A_range, alpha_range, B_range, beta_range))\n",
    "\n",
    "# Step 5: Fit using L-BFGS-B\n",
    "best_result = None\n",
    "lowest_mse = np.inf\n",
    "\n",
    "for guess in tqdm(initial_guesses):\n",
    "    result = minimize(huber_loss, x0=guess, args=(N, D, targets), method=\"L-BFGS-B\")\n",
    "    if result.success:\n",
    "        current_mse = huber_loss(result.x, N, D, targets)\n",
    "        if current_mse < lowest_mse:\n",
    "            lowest_mse = current_mse\n",
    "            best_result = result\n",
    "\n",
    "# Step 6: Show the results\n",
    "if best_result:\n",
    "    E_opt, A_opt, alpha_opt, B_opt, beta_opt = best_result.x\n",
    "    print(f\"E     = {E_opt:.6f}\")\n",
    "    print(f\"A     = {A_opt:.6f}\")\n",
    "    print(f\"alpha = {alpha_opt:.6f}\")\n",
    "    print(f\"B     = {B_opt:.6f}\")\n",
    "    print(f\"beta  = {beta_opt:.6f}\")\n",
    "    print(f\"Loss  = {lowest_mse:.6f}\")\n",
    "else:\n",
    "    print(\"Optimization failed for all initial guesses.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765e362",
   "metadata": {},
   "source": [
    "# Find the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee1dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DCLM scale</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>padded_vocab_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>ffn_hidden_size</th>\n",
       "      <th>moe_ffn_hidden_size</th>\n",
       "      <th>num_experts</th>\n",
       "      <th>moe_router_topk</th>\n",
       "      <th>active_params</th>\n",
       "      <th>total_params</th>\n",
       "      <th>tokens</th>\n",
       "      <th>predicted_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400M-1x</td>\n",
       "      <td>2.000000e+19</td>\n",
       "      <td>12</td>\n",
       "      <td>50304</td>\n",
       "      <td>1024</td>\n",
       "      <td>5472</td>\n",
       "      <td>704</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>354.9M</td>\n",
       "      <td>1.7B</td>\n",
       "      <td>9.392317e+09</td>\n",
       "      <td>3.083589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400M-4x</td>\n",
       "      <td>8.000000e+19</td>\n",
       "      <td>18</td>\n",
       "      <td>50304</td>\n",
       "      <td>1536</td>\n",
       "      <td>8208</td>\n",
       "      <td>1056</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0B</td>\n",
       "      <td>5.8B</td>\n",
       "      <td>1.333333e+10</td>\n",
       "      <td>2.879024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1B-1x</td>\n",
       "      <td>2.400000e+20</td>\n",
       "      <td>21</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0B</td>\n",
       "      <td>12.0B</td>\n",
       "      <td>2.000000e+10</td>\n",
       "      <td>2.752687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1B-3x</td>\n",
       "      <td>7.200000e+20</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>4.800000e+10</td>\n",
       "      <td>2.665371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3B-1x</td>\n",
       "      <td>9.400000e+20</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>6.266667e+10</td>\n",
       "      <td>2.652439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1B-5x</td>\n",
       "      <td>1.200000e+21</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>8.000000e+10</td>\n",
       "      <td>2.642575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7B-1x</td>\n",
       "      <td>5.700000e+21</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>3.800000e+11</td>\n",
       "      <td>2.607853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7B-2x</td>\n",
       "      <td>1.100000e+22</td>\n",
       "      <td>27</td>\n",
       "      <td>50304</td>\n",
       "      <td>2048</td>\n",
       "      <td>10944</td>\n",
       "      <td>1408</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5B</td>\n",
       "      <td>15.5B</td>\n",
       "      <td>7.333333e+11</td>\n",
       "      <td>2.601495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DCLM scale         FLOPs  num_layers  padded_vocab_size  hidden_size  \\\n",
       "0    400M-1x  2.000000e+19          12              50304         1024   \n",
       "1    400M-4x  8.000000e+19          18              50304         1536   \n",
       "2      1B-1x  2.400000e+20          21              50304         2048   \n",
       "3      1B-3x  7.200000e+20          27              50304         2048   \n",
       "4      3B-1x  9.400000e+20          27              50304         2048   \n",
       "5      1B-5x  1.200000e+21          27              50304         2048   \n",
       "6      7B-1x  5.700000e+21          27              50304         2048   \n",
       "7      7B-2x  1.100000e+22          27              50304         2048   \n",
       "\n",
       "   ffn_hidden_size  moe_ffn_hidden_size  num_experts  moe_router_topk  \\\n",
       "0             5472                  704           64                8   \n",
       "1             8208                 1056           64                8   \n",
       "2            10944                 1408           64                8   \n",
       "3            10944                 1408           64                8   \n",
       "4            10944                 1408           64                8   \n",
       "5            10944                 1408           64                8   \n",
       "6            10944                 1408           64                8   \n",
       "7            10944                 1408           64                8   \n",
       "\n",
       "  active_params total_params        tokens  predicted_loss  \n",
       "0        354.9M         1.7B  9.392317e+09        3.083589  \n",
       "1          1.0B         5.8B  1.333333e+10        2.879024  \n",
       "2          2.0B        12.0B  2.000000e+10        2.752687  \n",
       "3          2.5B        15.5B  4.800000e+10        2.665371  \n",
       "4          2.5B        15.5B  6.266667e+10        2.652439  \n",
       "5          2.5B        15.5B  8.000000e+10        2.642575  \n",
       "6          2.5B        15.5B  3.800000e+11        2.607853  \n",
       "7          2.5B        15.5B  7.333333e+11        2.601495  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_count(s: str) -> int:\n",
    "    s = s.strip().upper()\n",
    "    if s.endswith(\"B\"):\n",
    "        return int(float(s[:-1]) * 1_000_000_000)\n",
    "    elif s.endswith(\"M\"):\n",
    "        return int(float(s[:-1]) * 1_000_000)\n",
    "    elif s.endswith(\"K\"):\n",
    "        return int(float(s[:-1]) * 1_000)\n",
    "    return int(float(s))\n",
    "\n",
    "def scaling_law(N, D):\n",
    "    # Obtained from MSE \n",
    "    # E, A, alpha, B, beta = 2.133594, 65.254366, 0.226854, 485165195.409790, 0.949495\n",
    "    # Obtained from Huber\n",
    "    E, A, alpha, B, beta = 2.242056, 148.412995, 0.279724, 3269017.372472, 0.715505\n",
    "    return E + A / (N**alpha) + B / (D**beta)\n",
    "\n",
    "# Step 1: Load and transform\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1sIr9HRwYbUXKzlskUTMorMa2A_cAzDwE0eUJnk-W1dQ/export?format=csv&gid=599230821\")\n",
    "\n",
    "# Step 2: Define budgets\n",
    "budgets = [6e18, 1e19, 3e19, 6e19, 1e20, 3e20, 6e20, 1e21, 3e21, 6e21]\n",
    "budgets = [2e19, 8e19, 2.4e20, 7.2e20, 9.4e20, 1.2e21, 5.7e21, 1.1e22]\n",
    "\n",
    "# Step 3: Compute predicted loss and best configs\n",
    "merged = []\n",
    "for budget in budgets:\n",
    "    df[\"FLOPs\"] = budget\n",
    "    df[\"tokens\"] = budget / (6 * df[\"active_params\"].apply(parse_count))\n",
    "    df[\"predicted_loss\"] = scaling_law(df[\"active_params\"].apply(parse_count), df[\"tokens\"])\n",
    "    tops = df.nsmallest(1, \"predicted_loss\")\n",
    "    merged.append(tops)\n",
    "\n",
    "df = pd.concat(merged, ignore_index=True)\n",
    "df[\"DCLM scale\"] = [\"400M-1x\", \"400M-4x\", \"1B-1x\", \"1B-3x\", \"3B-1x\", \"1B-5x\", \"7B-1x\", \"7B-2x\"]\n",
    "df = df[[\"DCLM scale\", \"FLOPs\"] + [col for col in df.columns if col != \"DCLM scale\" and col != \"FLOPs\"]]\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
